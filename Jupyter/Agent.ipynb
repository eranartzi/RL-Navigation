{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T17:37:09.356680Z",
     "start_time": "2019-05-01T17:37:09.353598Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T17:37:09.647272Z",
     "start_time": "2019-05-01T17:37:09.644591Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from QNetwork import QNetwork\n",
    "from ReplayBuffer import ReplayBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T17:37:09.964608Z",
     "start_time": "2019-05-01T17:37:09.961307Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = int(1e5)  # replay buffer size\n",
    "BATCH_SIZE = 64         # minibatch size\n",
    "GAMMA = 0.99            # discount factor\n",
    "TAU = 1e-3              # for soft update of target parameters\n",
    "LR = 5e-4               # learning rate \n",
    "UPDATE_EVERY = 4        # how often to update the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T17:37:13.023894Z",
     "start_time": "2019-05-01T17:37:13.020574Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    \n",
    "    def __init__(self, state_size, action_size, seed):\n",
    "        # create the local and target Qnetworks\n",
    "        # create the memory buffer\n",
    "        # counter for steps to learn\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.seed = random.seed(seed)\n",
    "        \n",
    "        self.qn_local = QNetwork(state_size, action_size, seed=seed).to(device)\n",
    "        self.qn_target = QNetwork(state_size, action_size, seed=seed).to(device)\n",
    "        self.optimizer = optim.Adam(params=self.qn_local.parameters(), lr=LR)\n",
    "        \n",
    "        self.memory = ReplayBuffer(action_size, BUFFER_SIZE, BATCH_SIZE, seed)\n",
    "        self.t_step = 0\n",
    "    \n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "        self.memory.add(state, action, reward, next_state, done)\n",
    "        self.t_step = (self.t_step + 1) % UPDATE_EVERY\n",
    "        if self.t_step == 0:\n",
    "            experiences = self.memory.sample()\n",
    "            self.learn(experiences, GAMMA)\n",
    "    \n",
    "    def act(self, state, eps=0.):\n",
    "        # implement an epsilon greedy policy\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "        self.qn_local.eval()\n",
    "        with torch.no_grad():\n",
    "            action_values = self.qn_local(state)\n",
    "        self.qn_local.train()\n",
    "        if random.random() > eps:\n",
    "            return np.argmax(action_values.cpu().data.numpy())\n",
    "        else:\n",
    "            return random.choice(np.arange(self.action_size))\n",
    "     \n",
    "    def learn(self, experiences, gamma):\n",
    "        # collect experience tuples in memory and learn every S steps\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "        \n",
    "        Q_targets_next = self.qn_target(next_states).detach().max(1)[0].unsqueeze(1)\n",
    "        Q_targets = rewards + (gamma * Q_targets_next * (1 - dones))\n",
    "        \n",
    "        Q_expected = self.qn_local(states).gather(1, actions)\n",
    "        \n",
    "        loss = F.mse_loss(Q_expected, Q_targets)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        self.soft_update(local_model=self.qn_local, target_model=self.qn_target, tau=TAU)  \n",
    "        \n",
    "    def soft_update(self, local_model, target_model, tau):\n",
    "        # Update the local target network with the local network params\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "382px",
    "left": "1578px",
    "right": "20px",
    "top": "111px",
    "width": "413px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
